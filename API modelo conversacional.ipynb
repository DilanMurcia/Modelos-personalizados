{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd35878a5b144f3da18284220fc4b0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdf544bbd7544f02870c76ee83c0bac2",
              "IPY_MODEL_4889bd1a1cad4d9aab043dbf22109d15",
              "IPY_MODEL_7c21b72da54d4328bb3f0b3b264537ed"
            ],
            "layout": "IPY_MODEL_84645b3b6c84488881be2379caadc0b1"
          }
        },
        "bdf544bbd7544f02870c76ee83c0bac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3581421e3cd24c20abde67ebc09d6fd1",
            "placeholder": "​",
            "style": "IPY_MODEL_0777dac2454e46e6be4258b42cf58be4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4889bd1a1cad4d9aab043dbf22109d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e43fe7f93a34f3785400112fa807de5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1e8a20bcaf548348fce12ffc0979d1e",
            "value": 2
          }
        },
        "7c21b72da54d4328bb3f0b3b264537ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3fb313756a4f40876cd1806654c962",
            "placeholder": "​",
            "style": "IPY_MODEL_8309c851974e448e811dc5400d6598fa",
            "value": " 2/2 [00:40&lt;00:00, 16.80s/it]"
          }
        },
        "84645b3b6c84488881be2379caadc0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3581421e3cd24c20abde67ebc09d6fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0777dac2454e46e6be4258b42cf58be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e43fe7f93a34f3785400112fa807de5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e8a20bcaf548348fce12ffc0979d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e3fb313756a4f40876cd1806654c962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8309c851974e448e811dc5400d6598fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Relimpieza de paquetes si llega a ser necesario"
      ],
      "metadata": {
        "id": "lf1Bq-Mtu2_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y gradio diffusers sentence-transformers peft\n",
        "# ¡Limpieza y reinstalación!\n",
        "!pip uninstall -y transformers accelerate huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uEmkvOBmuWD0",
        "outputId": "ca06370d-b391-4cc7-e38e-d3ad3ef03170"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping gradio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping diffusers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping sentence-transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: transformers 4.41.1\n",
            "Uninstalling transformers-4.41.1:\n",
            "  Successfully uninstalled transformers-4.41.1\n",
            "Found existing installation: accelerate 1.7.0\n",
            "Uninstalling accelerate-1.7.0:\n",
            "  Successfully uninstalled accelerate-1.7.0\n",
            "Found existing installation: huggingface-hub 0.28.1\n",
            "Uninstalling huggingface-hub-0.28.1:\n",
            "  Successfully uninstalled huggingface-hub-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalación de dependencias"
      ],
      "metadata": {
        "id": "uRxT1eLwsKhl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "imDX3Ij3hkZv"
      },
      "outputs": [],
      "source": [
        "# Instalar versiones compatibles y recientes (evita conflictos con gradio, peft, etc.)\n",
        "!pip install --upgrade transformers==4.41.1 accelerate pyngrok huggingface_hub==0.28.1 --quiet\n",
        "\n",
        "# Importaciones\n",
        "from pyngrok import ngrok\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "import threading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Login y descarga del modelo conversacional"
      ],
      "metadata": {
        "id": "UwdGfjrysead"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Paso 1: Autenticarse con HuggingFace\n",
        "login(\"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\")  # tu token\n",
        "\n",
        "# Paso 2: Cargar modelo\n",
        "MODEL_NAME = \"google/gemma-2b-it\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    use_auth_token=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "fd35878a5b144f3da18284220fc4b0c9",
            "bdf544bbd7544f02870c76ee83c0bac2",
            "4889bd1a1cad4d9aab043dbf22109d15",
            "7c21b72da54d4328bb3f0b3b264537ed",
            "84645b3b6c84488881be2379caadc0b1",
            "3581421e3cd24c20abde67ebc09d6fd1",
            "0777dac2454e46e6be4258b42cf58be4",
            "5e43fe7f93a34f3785400112fa807de5",
            "d1e8a20bcaf548348fce12ffc0979d1e",
            "5e3fb313756a4f40876cd1806654c962",
            "8309c851974e448e811dc5400d6598fa"
          ]
        },
        "id": "WmDE14UHkoSY",
        "outputId": "8ffada94-f622-4eea-fed9-6d9d3eb92950",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd35878a5b144f3da18284220fc4b0c9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tunear la personalidad y proposito del agente"
      ],
      "metadata": {
        "id": "ud02Ev_Y_nt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def responder(prompt):\n",
        "    # Instrucción incluida directamente como parte del mensaje para Gemma\n",
        "    system_instruction = \"Eres un agente de atención al cliente amable, claro y eficiente. Responde solo una vez y no continúes la conversación.\"\n",
        "\n",
        "    # Unimos todo en un solo prompt plano, como requiere Gemma\n",
        "    chat_prompt = f\"{system_instruction}\\nCliente: {prompt}\\nAgente:\"\n",
        "\n",
        "    # Tokenizar y preparar entrada\n",
        "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Generación\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=120,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decodificar sin repetir el prompt original\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    respuesta = decoded[len(chat_prompt):].strip()\n",
        "\n",
        "    # Recorte simple si el modelo intenta seguir el diálogo\n",
        "    respuesta = respuesta.split(\"Cliente:\")[0].strip()\n",
        "    respuesta = respuesta.split(\"Agente:\")[-1].strip() if \"Agente:\" in respuesta else respuesta\n",
        "\n",
        "    return respuesta\n",
        "\n"
      ],
      "metadata": {
        "id": "BKBIPqb6_5rQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plantillas para casos especificos"
      ],
      "metadata": {
        "id": "m77HkJSZAEkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_prompt(usuario_input):\n",
        "    return f\"\"\"\n",
        "Eres un asistente de servicio al cliente en una tienda de tecnología.\n",
        "Responde con amabilidad, usa un lenguaje sencillo y ofrece soluciones claras.\n",
        "\n",
        "Cliente: {usuario_input}\n",
        "Asistente:\n",
        "\"\"\".strip()\n"
      ],
      "metadata": {
        "id": "NmnhdhIEAHzo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configuración y despliegue de la API"
      ],
      "metadata": {
        "id": "D4gYjJzBsY-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class PromptInput(BaseModel):\n",
        "    message: str\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "def generate_response(prompt: PromptInput):\n",
        "    answer = responder(prompt.message)\n",
        "    return {\"response\": answer}\n",
        "\n",
        "\n",
        "# Ejecutar el servidor en segundo plano (Colab-friendly)\n",
        "def run_api():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "thread = threading.Thread(target=run_api)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "id": "FNqJ95pvhoMx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuro el token\n",
        "!ngrok config add-authtoken 2yKhiwVeJUvh3xPBj4nOBq8Tuz8_5N4xXNW2823PF4w1si89w\n",
        "# Abre el túnel a tu servidor local en el puerto 8000\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Tu API pública: {public_url}\")"
      ],
      "metadata": {
        "id": "jMQHxMW0pYFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434a7b7f-cd82-4981-ae24-582d84237dd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [23929]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Tu API pública: NgrokTunnel: \"https://b06b-34-23-164-137.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probando la API"
      ],
      "metadata": {
        "id": "aiZz0_fTtDjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "data = {\"message\": \"Hola, me interesa una camisa\"}\n",
        "\n",
        "url = f\"{public_url.public_url}/chat\"  # Usa directamente la variable public_url\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "6jxfpZ1hp7kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bdea044-826d-46be-a658-9ebb5a89bc78"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     34.23.164.137:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "200\n",
            "{'response': 'Hola! Soy su agente de atención. ¿Qué puedo hacer para usted hoy?\\n\\n**Pregunta adicional:** ¿Qué tipo de camisa está buscando?'}\n"
          ]
        }
      ]
    }
  ]
}